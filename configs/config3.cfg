[ENVIRONMENT]
map_file = map3.txt
reward_per_step = 0.0 
reward_outside_grid = 0.0
reward_duplicate_beep = 0.0
tg_reward = 500.0
reward_ldlf =  <!red*; red; !yellow*; yellow; !blue*; blue>end
max_timesteps = 400
name_dir_experiment = case3

[AGENT]
algorithm = PPO
initial_position_x = 0
initial_position_y = 0
max_velocity = 0.4
min_velocity = 0.0
acceleration = 0.2
angular_acceleration = 10.0

[TENSORFORCE]
batch_size = 128
memory = 128
learning_rate_initial_value = 0.001
learning_rate_final_value = 0.00001
exploration_initial_value = 0.8
exploration_final_value = 0.005
learning_rate_decay_value = 0.0000025
exploration_decay_value = 0.00
entropy_bonus = 0.0
hidden_size = 64
discount = 0.99
update_frequency = 20
target_sync_frequency = 3
target_update_weights = 0.8

[RUNNER]
episodes = 1500
goal_reward_reduction_rate = 0.65