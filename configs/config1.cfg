[ENVIRONMENT]
map_file = map1.txt
reward_per_step = 0.0 
reward_outside_grid = 0.0
reward_duplicate_beep = 0.0
tg_reward = 500.0
reward_ldlf =  <!red*; red; !yellow*; yellow; !blue*; blue>end

[AGENT]
algorithm = PPO
initial_position_x = 0
initial_position_y = 0
max_velocity = 0.4
min_velocity = 0.0
acceleration = 0.2
angular_acceleration = 10.0

[TENSORFORCE]
batch_size = 48
memory = 500
max_timesteps = 400
episodes = 1000
learning_rate_initial_value = 0.001
learning_rate_final_value = 0.00001
exploration_initial_value = 0.75
exploration_final_value = 0.005
learning_rate_decay_value = 0.0000025
exploration_decay_value = 0.00
entropy_bonus = 0.0
hidden_size = 48
discount = 0.99
update_frequency = 48
target_sync_frequency = 3
target_update_weights = 0.8

[OTHER]
name_dir_experiment = case1
max_angular_vel = 40