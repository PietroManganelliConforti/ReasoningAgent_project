[ENVIRONMENT]
map_file = map1.txt
reward_per_step = 0.0
reward_outside_grid = 0.0
reward_duplicate_beep = 0.0
tg_reward = 1.0
reward_ldlf = <!red*; red>end

[AGENT]
initial_position_x = 0
initial_position_y = 0
max_velocity = 0.4
min_velocity = 0.0
acceleration = 0.2
angular_acceleration = 10.0

[OTHER]
name_dir_experiment = case1
max_angular_vel = 40
colors = red
num_colors = 1

[TENSORFORCE]
batch_size = 64
memory = 300
multi_step = 10
update_frequency = 64 
learning_rate = 0.001
exploration = 0.0
entropy_bonus = 0.0
hidden_size = 64
max_timesteps = 300
episodes = 1000